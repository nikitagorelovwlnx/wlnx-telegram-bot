/**
 * Fixed tests for ConversationService - only test what's actually implemented
 */

import { conversationService } from '../../services/conversationService';
import { ConversationMessage, WellnessData } from '../../types';

// Mock OpenAI
jest.mock('openai', () => {
  const mockCreate = jest.fn();
  return {
    __esModule: true,
    default: jest.fn().mockImplementation(() => ({
      chat: {
        completions: {
          create: mockCreate
        }
      }
    }))
  };
});

describe('ConversationService - Fixed Tests', () => {
  });

  describe('generateResponse', () => {
    const mockOpenAI = require('openai').default;
    let mockCreate: jest.Mock;

    beforeEach(() => {
      mockCreate = mockOpenAI().chat.completions.create;
    });

    it('should generate response with proper OpenAI call', async () => {
      const mockResponse = {
        choices: [{
          message: {
            content: 'Hello! How are you today?'
          }
        }]
      };

      mockCreate.mockResolvedValue(mockResponse);

      const conversation: ConversationMessage[] = [
        {
          role: 'user',
          content: 'Hi Anna!',
          timestamp: '2023-12-01T10:00:00Z'
        }
      ];

      const result = await conversationService.generateResponse(conversation);

      expect(result).toBe('Hello! How are you today?');
      
      // Should use GPT-5 or fallback to GPT-4
      const calls = mockCreate.mock.calls;
      expect(calls.length).toBeGreaterThanOrEqual(1);
      
      // Check that at least one call has the right parameters
      const validCall = calls.find(call => 
        call[0].model === 'gpt-5' || call[0].model === 'gpt-4'
      );
      expect(validCall).toBeDefined();
      // Now conversationService just passes messages directly without system prompts
      expect(validCall[0].messages).toEqual([
        expect.objectContaining({
          role: 'user',
          content: 'Hi Anna!'
        })
      ]);
      expect(validCall[0].temperature).toBe(0.7);
      
      if (validCall[0].model === 'gpt-5') {
        expect(validCall[0].max_completion_tokens).toBe(1500);
      } else {
        expect(validCall[0].max_tokens).toBe(1500);
      }
    });

    it('should handle OpenAI API errors', async () => {
      mockCreate.mockRejectedValue(new Error('API Error'));

      const conversation: ConversationMessage[] = [
        {
          role: 'user',
          content: 'Hi Anna!',
          timestamp: '2023-12-01T10:00:00Z'
        }
      ];

      const result = await conversationService.generateResponse(conversation);

      expect(result).toBe('Sorry, something went wrong ðŸ˜… Can you try again?');
    });

    it('should handle empty response from OpenAI', async () => {
      const mockResponse = {
        choices: []
      };

      mockCreate.mockResolvedValue(mockResponse);

      const conversation: ConversationMessage[] = [
        {
          role: 'user',
          content: 'Hi Anna!',
          timestamp: '2023-12-01T10:00:00Z'
        }
      ];

      const result = await conversationService.generateResponse(conversation);

      expect(result).toBe('Sorry, something went wrong ðŸ˜… Can you try again?');
    });
  });

  describe('generateWellnessSummary', () => {
    const mockOpenAI = require('openai').default;
    let mockCreate: jest.Mock;

    beforeEach(() => {
      mockCreate = mockOpenAI().chat.completions.create;
    });

    it('should generate wellness summary with extracted data', async () => {
      const mockSummary = '## WELLNESS PROFILE SUMMARY\n\n### DEMOGRAPHICS\n- Age: 30\n- Weight: 70kg';
      
      const mockResponse = {
        choices: [{
          message: {
            content: mockSummary
          }
        }]
      };

      mockCreate.mockResolvedValue(mockResponse);

      const conversation: ConversationMessage[] = [
        {
          role: 'user',
          content: "I'm 30 years old and weigh 70kg",
          timestamp: '2023-12-01T10:00:00Z'
        }
      ];

      const result = await conversationService.generateWellnessSummary(conversation);

      expect(result).toBe(mockSummary);
      
      // Check that OpenAI was called with either GPT-5 or GPT-4
      const calls = mockCreate.mock.calls;
      expect(calls.length).toBeGreaterThanOrEqual(1);
      
      // At least one call should be with a valid model
      const hasValidModel = calls.some(call => 
        call[0].model === 'gpt-5' || call[0].model === 'gpt-4'
      );
      expect(hasValidModel).toBe(true);
    });

    it('should handle summary generation errors', async () => {
      mockCreate.mockRejectedValue(new Error('Summary generation failed'));

      const conversation: ConversationMessage[] = [
        {
          role: 'user',
          content: 'Test message',
          timestamp: '2023-12-01T10:00:00Z'
        }
      ];

      await expect(conversationService.generateWellnessSummary(conversation))
        .rejects.toThrow('Summary generation failed');
    });
  });

  describe('isAvailable', () => {
    it('should return true when OpenAI is configured', () => {
      expect(conversationService.isAvailable()).toBe(true);
    });
  });
});
